{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91d8f18",
   "metadata": {},
   "source": [
    "# Notebook 1 - Simple Analyzer\n",
    "\n",
    "This notebook takes CMS OpenData nanoAOD files, applies some selection and make few simple plots. \n",
    "\n",
    "Expected output: Histograms with the event selection.\n",
    "\n",
    "Physics objects of interest: muons and jets. \n",
    "\n",
    "For more information: https://github.com/HEP-EPN/FourTopsCMSOpenData/wiki. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b5f6f",
   "metadata": {},
   "source": [
    "Let's first load the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76764285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import vector; vector.register_awkward() \n",
    "import awkward as ak\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import transforms\n",
    "from coffea.nanoevents.methods import base, vector\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "import hist\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89775383",
   "metadata": {},
   "source": [
    "For future use, let's define some global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a6c4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL CONFIGURATION\n",
    "\n",
    "# input files per process, set to e.g. 10 (smaller number = faster)\n",
    "N_FILES_MAX_PER_SAMPLE = 5\n",
    "\n",
    "### BENCHMARKING-SPECIFIC SETTINGS\n",
    "\n",
    "# chunk size to use\n",
    "CHUNKSIZE = 500_000\n",
    "\n",
    "# metadata to propagate through to metrics\n",
    "CORES_PER_WORKER = 2  # does not do anything, only used for metric gathering (set to 2 for distributed coffea-casa)\n",
    "\n",
    "# scaling for local setups with FuturesExecutor\n",
    "NUM_CORES = 4\n",
    "\n",
    "# only I/O, all other processing disabled\n",
    "DISABLE_PROCESSING = False\n",
    "\n",
    "# read additional branches (only with DISABLE_PROCESSING = True)\n",
    "# acceptable values are 2.7, 4, 15, 25, 50 (corresponding to % of file read), 2.7% corresponds to the standard branches used in the notebook\n",
    "IO_FILE_PERCENT = 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cb6b1",
   "metadata": {},
   "source": [
    "NanoAOD datasets are stored in `data/ntuples_nanoaod.json` folder. This json file contains information about the number of events, process and systematic. The following function reads the json file and returns a dictionary with the process to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58a76cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fileset(n_files_max_per_sample, \n",
    "                      use_xcache=False, \n",
    "                      onlyNominal=False,\n",
    "                      ntuples_json=\"ntuples_nanoaod.json\"):\n",
    "    # using https://atlas-groupdata.web.cern.ch/atlas-groupdata/dev/AnalysisTop/TopDataPreparation/XSection-MC15-13TeV.data\n",
    "    # for reference\n",
    "    # x-secs are in pb\n",
    "    \n",
    "    xsec_info = {\n",
    "        \"tttt\":0, #change this value in pbrn\n",
    "        \"ttbar\": 396.87 + 332.97, # nonallhad + allhad, keep same x-sec for all\n",
    "        \"single_top_s_chan\": 2.0268 + 1.2676,\n",
    "        \"single_top_t_chan\": (36.993 + 22.175)/0.252,  # scale from lepton filter to inclusive\n",
    "        \"single_top_tW\": 37.936 + 37.906,\n",
    "        \"wjets\": 61457 * 0.252,  # e/mu+nu final states\n",
    "        \"data\": None\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # list of files\n",
    "    with open(ntuples_json) as f:\n",
    "        file_info = json.load(f)\n",
    "\n",
    "    # process into \"fileset\" summarizing all info\n",
    "    fileset = {}\n",
    "    \n",
    "    #with .keys() method we access the dictionary\n",
    "    for process in file_info.keys():\n",
    "        if process == \"data\":\n",
    "            continue  # skip data\n",
    "\n",
    "        for variation in file_info[process].keys():\n",
    "            if onlyNominal & ~variation.startswith(\"nominal\"): continue\n",
    "            print(variation)\n",
    "            file_list = file_info[process][variation][\"files\"]\n",
    "            if n_files_max_per_sample != -1:\n",
    "                file_list = file_list[:n_files_max_per_sample]  # use partial set of samples\n",
    "\n",
    "            file_paths = [f[\"path\"] for f in file_list]\n",
    "            nevts_total = sum([f[\"nevts\"] for f in file_list])\n",
    "            metadata = {\"process\": process, \"variation\": variation, \"nevts\": nevts_total, \"xsec\": xsec_info[process]}\n",
    "            fileset.update({f\"{process}__{variation}\": {\"files\": file_paths, \"metadata\": metadata}})\n",
    "\n",
    "    return fileset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6873da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nominal\n",
      "nominal\n",
      "nominal\n",
      "nominal\n",
      "nominal\n",
      "processes in fileset: ['ttbar__nominal', 'single_top_s_chan__nominal', 'single_top_t_chan__nominal', 'single_top_tW__nominal', 'wjets__nominal']\n",
      "\n",
      "example of information in fileset:\n",
      "{\n",
      "  'files': [https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root, ...],\n",
      "  'metadata': {'process': 'ttbar', 'variation': 'nominal', 'nevts': 6389801, 'xsec': 729.84}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "fileset = construct_fileset(N_FILES_MAX_PER_SAMPLE, use_xcache=False, \n",
    "                            onlyNominal=True, ntuples_json='../Tesis/ntuples_nanoaod.json') \n",
    "\n",
    "print(f\"processes in fileset: {list(fileset.keys())}\")\n",
    "print(f\"\\nexample of information in fileset:\\n{{\\n  'files': [{fileset['ttbar__nominal']['files'][0]}, ...],\")\n",
    "print(f\"  'metadata': {fileset['ttbar__nominal']['metadata']}\\n}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed54bc2",
   "metadata": {},
   "source": [
    "## Analyzer\n",
    "\n",
    "Here is the main analyzer. Uses coffea/awkward to make the analysis.\n",
    "\n",
    "Advice: to understand how the selection is working, print the differents arrays before and after the selections are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c01ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TtbarAnalysis(processor.ProcessorABC):\n",
    "    def __init__(self, disable_processing, io_file_percent):\n",
    "        num_bins = 25\n",
    "        bin_low = 50\n",
    "        bin_high = 550\n",
    "        name = \"observable\"\n",
    "        label = \"observable [GeV]\"\n",
    "        \n",
    "        #histrogram\n",
    "        self.hist = (\n",
    "            hist.Hist.new.Reg(num_bins, bin_low, bin_high, name=name, label=label)\n",
    "            .StrCat([\"4j1b\", \"4j2b\"], name=\"region\", label=\"Region\")\n",
    "            .StrCat([], name=\"process\", label=\"Process\", growth=True)\n",
    "            .StrCat([], name=\"variation\", label=\"Systematic variation\", growth=True)\n",
    "            .Weight()\n",
    "        )\n",
    "        self.disable_processing = disable_processing\n",
    "        self.io_file_percent = io_file_percent #2.7\n",
    "\n",
    "    def only_do_IO(self, events):\n",
    "        # standard AGC branches cover 2.7% of the data\n",
    "            branches_to_read = []\n",
    "            if self.io_file_percent >= 2.7:\n",
    "                branches_to_read.extend([\"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_btagCSVV2\", \"Jet_mass\", \"Muon_pt\", \"Electron_pt\", \"HLT.IsoMu18\"])\n",
    "            \n",
    "            if self.io_file_percent >= 4:\n",
    "                branches_to_read.extend([\"Electron_phi\", \"Electron_eta\",\"Electron_mass\",\"Muon_phi\",\"Muon_eta\",\"Muon_mass\",\n",
    "                                         \"Photon_pt\",\"Photon_eta\",\"Photon_mass\",\"Jet_jetId\"])\n",
    "            \n",
    "            if self.io_file_percent>=15:\n",
    "                branches_to_read.extend([\"Jet_nConstituents\",\"Jet_electronIdx1\",\"Jet_electronIdx2\",\"Jet_muonIdx1\",\"Jet_muonIdx2\",\n",
    "                                         \"Jet_chHEF\",\"Jet_area\",\"Jet_puId\",\"Jet_qgl\",\"Jet_btagDeepB\",\"Jet_btagDeepCvB\",\n",
    "                                         \"Jet_btagDeepCvL\",\"Jet_btagDeepFlavB\",\"Jet_btagDeepFlavCvB\",\"Jet_btagDeepFlavCvL\",\n",
    "                                         \"Jet_btagDeepFlavQG\",\"Jet_chEmEF\",\"Jet_chFPV0EF\",\"Jet_muEF\",\"Jet_muonSubtrFactor\",\n",
    "                                         \"Jet_neEmEF\",\"Jet_neHEF\",\"Jet_puIdDisc\"])\n",
    "            \n",
    "            if self.io_file_percent>=25:\n",
    "                branches_to_read.extend([\"Jet_rawFactor\",\"Jet_bRegCorr\",\"Jet_bRegRes\",\"Jet_cRegCorr\",\"Jet_cRegRes\",\"Jet_nElectrons\",\n",
    "                                         \"Jet_nMuons\",\"GenJet_pt\",\"GenJet_eta\",\"GenJet_phi\",\"GenJet_mass\",\"Tau_pt\",\"Tau_eta\",\"Tau_mass\",\n",
    "                                         \"Tau_phi\",\"Muon_dxy\",\"Muon_dxyErr\",\"Muon_dxybs\",\"Muon_dz\",\"Muon_dzErr\",\"Electron_dxy\",\n",
    "                                         \"Electron_dxyErr\",\"Electron_dz\",\"Electron_dzErr\",\"Electron_eInvMinusPInv\",\"Electron_energyErr\",\n",
    "                                         \"Electron_hoe\",\"Electron_ip3d\",\"Electron_jetPtRelv2\",\"Electron_jetRelIso\",\n",
    "                                         \"Electron_miniPFRelIso_all\",\"Electron_miniPFRelIso_chg\",\"Electron_mvaFall17V2Iso\",\n",
    "                                         \"Electron_mvaFall17V2noIso\",\"Electron_pfRelIso03_all\",\"Electron_pfRelIso03_chg\",\"Electron_r9\",\n",
    "                                         \"Electron_scEtOverPt\",\"Electron_sieie\",\"Electron_sip3d\",\"Electron_mvaTTH\",\"Electron_charge\",\n",
    "                                         \"Electron_cutBased\",\"Electron_jetIdx\",\"Electron_pdgId\",\"Electron_photonIdx\",\"Electron_tightCharge\"])\n",
    "            \n",
    "            if self.io_file_percent==50:\n",
    "                branches_to_read.extend([\"GenPart_pt\",\"GenPart_eta\",\"GenPart_phi\",\"GenPart_mass\",\"GenPart_genPartIdxMother\",\n",
    "                                         \"GenPart_pdgId\",\"GenPart_status\",\"GenPart_statusFlags\"])\n",
    "                \n",
    "            if self.io_file_percent not in [2.7, 4, 15, 25, 50]:\n",
    "                raise NotImplementedError(\"supported values for I/O percentage are 4, 15, 25, 50\")\n",
    "            \n",
    "            for branch in branches_to_read:\n",
    "                if \"_\" in branch:\n",
    "                    split = branch.split(\"_\")\n",
    "                    object_type = split[0]\n",
    "                    property_name = '_'.join(split[1:])\n",
    "                    ak.materialized(events[object_type][property_name])\n",
    "                else:\n",
    "                    ak.materialized(events[branch])\n",
    "            return {\"hist\": {}}\n",
    "\n",
    "    def process(self, events):\n",
    "        if self.disable_processing:\n",
    "            # IO testing with no subsequent processing\n",
    "            return self.only_do_IO(events)\n",
    "\n",
    "        histogram = self.hist.copy()\n",
    "\n",
    "        process = events.metadata[\"process\"]  # \"ttbar\" etc.\n",
    "        \n",
    "        # normalization for MC\n",
    "        x_sec = events.metadata[\"xsec\"]\n",
    "        nevts_total = events.metadata[\"nevts\"]\n",
    "        lumi = 3378 # /pb\n",
    "        if process != \"data\":\n",
    "            xsec_weight = x_sec * lumi / nevts_total\n",
    "        else:\n",
    "            xsec_weight = 1\n",
    "\n",
    "        events[\"pt_nominal\"] = 1.0\n",
    "\n",
    "        ### EVENT SELECTION\n",
    "        # very very loosely based on https://arxiv.org/abs/2006.13076\n",
    "\n",
    "        #trigger selection (1 value per event)\n",
    "        selected_triggers=((events.HLT.IsoMu18)==1) # output = true, trigger is fired\n",
    "        \n",
    "        #basic selection\n",
    "        # pT > 26 GeV for muons & jets\n",
    "        selected_muons = events.Muon[(events.Muon.pt > 26) & (events.Muon.tightId==1)] # [[muon 1], [muon 1, muon 2],..]\n",
    "        selected_muon=(ak.count(selected_muons.pt, axis=1))==1\n",
    "        veto_muons=events.Muon[events.Muon.pt > 10] #  veto additional lose muon\n",
    "        veto_muon=(ak.count(veto_muons.pt,axis=1)== 0)\n",
    "        \n",
    "        jet_filter = events.Jet.pt * events[\"pt_nominal\"] > 26  # pT > 26 GeV for jets (scaled by systematic variations)\n",
    "        selected_jets = events.Jet[jet_filter]\n",
    "\n",
    "        # single lepton requirement\n",
    "        event_filters = selected_muon & veto_muon\n",
    "        # at least four jets\n",
    "        pt_var_modifier = events[\"pt_nominal\"]\n",
    "        event_filters = event_filters & (ak.count(selected_jets.pt * pt_var_modifier, axis=1) >= 4) #High jet multiplicity in tttt signal events\n",
    "        # at least one b-tagged jet (\"tag\" means score above threshold)\n",
    "        B_TAG_THRESHOLD = 0.8 #High b-jet multiplicity in both tt and tttt\n",
    "        event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "\n",
    "        # apply event filters\n",
    "        #take into account that up to this point we have been adding app all the event filters\n",
    "        selected_events = events[event_filters]\n",
    "        selected_muons = selected_muons[event_filters]\n",
    "        selected_jets = selected_jets[event_filters]\n",
    "\n",
    "        for region in [\"4j1b\", \"4j2b\"]:\n",
    "            # further filtering: 4j1b CR with single b-tag, 4j2b SR with two or more tags\n",
    "            if region == \"4j1b\":\n",
    "                region_filter = ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) == 1\n",
    "                selected_jets_region = selected_jets[region_filter]\n",
    "                # use HT (scalar sum of jet pT) as observable\n",
    "                pt_var_modifier = events[event_filters][region_filter][\"pt_nominal\"]\n",
    "                observable = ak.sum(selected_jets_region.pt * pt_var_modifier, axis=-1)\n",
    "\n",
    "            elif region == \"4j2b\":\n",
    "                region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2\n",
    "                selected_jets_region = selected_jets[region_filter]\n",
    "\n",
    "                # reconstruct hadronic top as bjj system with largest pT\n",
    "                # the jet energy scale / resolution effect is not propagated to this observable at the moment\n",
    "                trijet = ak.combinations(selected_jets_region, 3, fields=[\"j1\", \"j2\", \"j3\"])  # trijet candidates\n",
    "                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3  # calculate four-momentum of tri-jet system\n",
    "                trijet[\"max_btag\"] = np.maximum(trijet.j1.btagCSVV2, np.maximum(trijet.j2.btagCSVV2, trijet.j3.btagCSVV2))\n",
    "                trijet = trijet[trijet.max_btag > B_TAG_THRESHOLD]  # at least one-btag in trijet candidates\n",
    "                # pick trijet candidate with largest pT and calculate mass of system\n",
    "                trijet_mass = trijet[\"p4\"][ak.argmax(trijet.p4.pt, axis=1, keepdims=True)].mass\n",
    "                observable = ak.flatten(trijet_mass)\n",
    "\n",
    "            ### histogram filling\n",
    "            \n",
    "            # nominal pT, but including 2-point systematics\n",
    "            histogram.fill(\n",
    "                    observable=observable, region=region, process=process,\n",
    "                    variation=\"nominal\", weight=xsec_weight\n",
    "                )\n",
    "\n",
    "            \n",
    "        output = {\"nevents\": {events.metadata[\"dataset\"]: len(events)}, \"hist\": histogram}\n",
    "\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37346f",
   "metadata": {},
   "source": [
    "Let's make it run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2903d0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e72aeccacc4ac18c8b7e4d335c61d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/23 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc09fc53f8b49338c09334ca24fc95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/46 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "executor = processor.FuturesExecutor(workers=NUM_CORES)\n",
    "\n",
    "run = processor.Runner(executor=executor, schema=NanoAODSchema, \n",
    "                       savemetrics=True, metadata_cache={}, chunksize=CHUNKSIZE)\n",
    "\n",
    "#filemeta = run.preprocess(fileset, treename=\"Events\")  # pre-processing\n",
    "\n",
    "t0 = time.monotonic()\n",
    "all_histograms, metrics = run(fileset, \"Events\", processor_instance=TtbarAnalysis(DISABLE_PROCESSING, IO_FILE_PERCENT))  # processing\n",
    "exec_time = time.monotonic() - t0\n",
    "all_histograms = all_histograms[\"hist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13d6e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_source = \"/data\" if fileset[\"ttbar__nominal\"][\"files\"][0].startswith(\"/data\") else \"https://xrootd-local.unl.edu:1094\" # TODO: xcache support\n",
    "#metrics.update({\"walltime\": exec_time, \"num_workers\": NUM_CORES, \"dataset_source\": dataset_source, \n",
    "#                \"n_files_max_per_sample\": N_FILES_MAX_PER_SAMPLE, \n",
    "#                \"cores_per_worker\": CORES_PER_WORKER, \"chunksize\": CHUNKSIZE, \"disable_processing\": DISABLE_PROCESSING, \"io_file_percent\": IO_FILE_PERCENT})#\n",
    "\n",
    "# save metrics to disk\n",
    "#if not os.path.exists(\"metrics\"):\n",
    "#    os.makedirs(\"metrics\")\n",
    "#timestamp = time.strftime('%Y%m%d-%H%M%S')\n",
    "#metric_file_name = f\"metrics/nanoAOD-{AF_NAME}-{timestamp}.json\"\n",
    "#with open(metric_file_name, \"w\") as f:\n",
    "#    f.write(json.dumps(metrics))\n",
    "\n",
    "#print(f\"metrics saved as {metric_file_name}\")\n",
    "#print(f\"event rate per worker (full execution time divided by NUM_CORES={NUM_CORES}): {metrics['entries'] / NUM_CORES / exec_time / 1_000:.2f} kHz\")\n",
    "#print(f\"event rate per worker (pure processtime): {metrics['entries'] / metrics['processtime'] / 1_000:.2f} kHz\")\n",
    "#print(f\"amount of data read: {metrics['bytesread']/1000**2:.2f} MB\")  # likely buggy: https://github.com/CoffeaTeam/coffea/issues/717\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a06cee",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Finally, let's make some simple plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd97fe14",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 3 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_519/302708684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"222222\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mall_histograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m120j\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4j1b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nominal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">= 4 jets, 1 b-tag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/hist/basehist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     def __setitem__(  # type: ignore\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/boost_histogram/_internal/hist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Axes: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0mnew_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mnew_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mreduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0mintegrations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpick_each\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintegrations\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 3 with size 0"
     ]
    }
   ],
   "source": [
    "mpl.style.use(\"ggplot\")\n",
    "plt.rcParams[\"axes.facecolor\"] = \"none\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"222222\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"222222\"\n",
    "plt.rcParams[\"xtick.color\"] = \"222222\"\n",
    "plt.rcParams[\"ytick.color\"] = \"222222\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams['text.color'] = \"222222\"\n",
    "\n",
    "all_histograms[120j::hist.rebin(2), \"4j1b\", :, \"nominal\"].stack(\"process\")[::-1].plot(stack=True, histtype=\"fill\", linewidth=1, edgecolor=\"grey\")\n",
    "plt.legend(frameon=False)\n",
    "plt.title(\">= 4 jets, 1 b-tag\")\n",
    "plt.xlabel(\"HT [GeV]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90bcbbbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 3 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_519/2218600352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_histograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4j2b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nominal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">= 4 jets, >= 2 b-tags\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$m_{bjj}$ [Gev]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/hist/basehist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     def __setitem__(  # type: ignore\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/boost_histogram/_internal/hist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Axes: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0mnew_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mnew_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mreduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0mintegrations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpick_each\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintegrations\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 3 with size 0"
     ]
    }
   ],
   "source": [
    "all_histograms[:, \"4j2b\", :, \"nominal\"].stack(\"process\")[::-1].plot(stack=True, histtype=\"fill\", linewidth=1,edgecolor=\"grey\")\n",
    "plt.legend(frameon=False)\n",
    "plt.title(\">= 4 jets, >= 2 b-tags\")\n",
    "plt.xlabel(\"$m_{bjj}$ [Gev]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790561c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81b96447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_histograms(all_histograms, fileset, filename):\n",
    "    nominal_samples = [sample for sample in fileset.keys() if \"nominal\" in sample]\n",
    "\n",
    "    all_histograms += 1e-6  # add minimal event count to all bins to avoid crashes when processing a small number of samples\n",
    "\n",
    "    #pseudo_data = (all_histograms[:, :, \"ttbar\", \"ME_var\"] + all_histograms[:, :, \"ttbar\", \"PS_var\"]) / 2  + all_histograms[:, :, \"wjets\", \"nominal\"]\n",
    "\n",
    "    with uproot.recreate(filename) as f:\n",
    "        for region in [\"4j1b\", \"4j2b\"]:\n",
    "            #f[f\"{region}_pseudodata\"] = pseudo_data[120j::hist.rebin(2), region]\n",
    "            for sample in nominal_samples:\n",
    "                sample_name = sample.split(\"__\")[0]\n",
    "                f[f\"{region}_{sample_name}\"] = all_histograms[120j::hist.rebin(2), region, sample_name, \"nominal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66c69eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_histograms(all_histograms, fileset, \"histograms.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42319227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
